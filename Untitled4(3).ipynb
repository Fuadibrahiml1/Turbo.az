{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize an empty list to store car results\n",
        "car_results = []\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "} # It's good practice to include headers to mimic a browser\n",
        "\n",
        "for page_number in range(1, 10): # Looping through 300 pages\n",
        "    url = f'https://turbo.az/autos?page={page_number}'\n",
        "    print(f\"Scraping page: {page_number}\")\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=10) # Added timeout for robustness\n",
        "        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request failed for page {page_number}: {e}\")\n",
        "        continue # Skip to the next page if request fails\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all car listing elements\n",
        "    listings = soup.find_all('div', {'class': 'products-i__bottom'})\n",
        "\n",
        "    if not listings:\n",
        "        print(f\"No listings found on page {page_number}. Stopping.\")\n",
        "        break\n",
        "\n",
        "    for el in listings:\n",
        "        name = None\n",
        "        price = None\n",
        "        currency = None\n",
        "        year = None\n",
        "        engine_power = None\n",
        "        km = None\n",
        "\n",
        "        mileage = None\n",
        "        city = None\n",
        "        brand = None\n",
        "        model = None\n",
        "        body_type = None\n",
        "        transmission = None\n",
        "\n",
        "        drive_type = None\n",
        "        number_of_seats = None\n",
        "        owners = None\n",
        "        condition = None\n",
        "        body_type = None\n",
        "        market_adapted_for = None\n",
        "\n",
        "        # Safely extract 'name'\n",
        "        name_tag = el.find('div', {'class': 'products-i__name products-i__bottom-text'})\n",
        "        if name_tag:\n",
        "            name = name_tag.text.strip()\n",
        "\n",
        "        # Safely extract 'price' and 'currency'\n",
        "        price_tag = el.find('div', {'class': 'products-i__price products-i__bottom-text'})\n",
        "        if price_tag:\n",
        "            full_price_text = price_tag.text.replace(' ', '').strip()\n",
        "            # Check if the text is not empty before slicing\n",
        "            if full_price_text:\n",
        "                currency = full_price_text[-1]\n",
        "                price = full_price_text[:-1]\n",
        "\n",
        "        # Safely extract 'year', 'engine_power', 'km'\n",
        "        attributes_tag = el.find('div', {'class': 'products-i__attributes products-i__bottom-text'})\n",
        "        if attributes_tag:\n",
        "            attributes_text = attributes_tag.text.strip()\n",
        "            parts = attributes_text.split(',')\n",
        "            if len(parts) > 0:\n",
        "                year = parts[0].strip()\n",
        "            if len(parts) > 1:\n",
        "                engine_power = parts[1].strip()\n",
        "            if len(parts) > 2:\n",
        "                km = parts[2].strip()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        car_results.append({\n",
        "            'name': name,\n",
        "            'price': price,\n",
        "            'currency': currency,\n",
        "            'year': year,\n",
        "            'engine_power': engine_power,\n",
        "            'km': km\n",
        "        })\n",
        "\n",
        "# Create DataFrame from the collected results\n",
        "cars = pd.DataFrame(car_results)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(\"\\nDataFrame created successfully. First 5 rows:\")\n",
        "print(cars.head())\n",
        "\n",
        "# Optional: Save to CSV"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8hBkC6mUfKx",
        "outputId": "eb1dbc94-ccdd-4a91-844f-df66ce2f544a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page: 1\n",
            "Request failed for page 1: 403 Client Error: Forbidden for url: https://turbo.az/autos?page=1\n",
            "Scraping page: 2\n",
            "Request failed for page 2: 403 Client Error: Forbidden for url: https://turbo.az/autos?page=2\n",
            "Scraping page: 3\n",
            "Request failed for page 3: 403 Client Error: Forbidden for url: https://turbo.az/autos?page=3\n",
            "Scraping page: 4\n",
            "Request failed for page 4: 403 Client Error: Forbidden for url: https://turbo.az/autos?page=4\n",
            "Scraping page: 5\n",
            "Request failed for page 5: 403 Client Error: Forbidden for url: https://turbo.az/autos?page=5\n",
            "Scraping page: 6\n",
            "Request failed for page 6: 403 Client Error: Forbidden for url: https://turbo.az/autos?page=6\n",
            "Scraping page: 7\n",
            "Request failed for page 7: 403 Client Error: Forbidden for url: https://turbo.az/autos?page=7\n",
            "Scraping page: 8\n",
            "Request failed for page 8: 403 Client Error: Forbidden for url: https://turbo.az/autos?page=8\n",
            "Scraping page: 9\n",
            "Request failed for page 9: 403 Client Error: Forbidden for url: https://turbo.az/autos?page=9\n",
            "\n",
            "DataFrame created successfully. First 5 rows:\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cars.to_csv('turbo_az_cars.csv', index=False)"
      ],
      "metadata": {
        "id": "aDddCv6CXD6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Initialize an empty list to store car results\n",
        "car_results = []\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "for page_number in range(1, 10):\n",
        "    url = f'https://turbo.az/autos?page={page_number}'\n",
        "    print(f\"Scraping page: {page_number}\")\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request failed for page {page_number}: {e}\")\n",
        "        continue\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all car listing elements\n",
        "    listings = soup.find_all('div', {'class': 'products-i__bottom'})\n",
        "\n",
        "    if not listings:\n",
        "        print(f\"No listings found on page {page_number}. Stopping.\")\n",
        "        break\n",
        "\n",
        "    for el in listings:\n",
        "        # Initialize all variables\n",
        "        name = None\n",
        "        price = None\n",
        "        currency = None\n",
        "        year = None\n",
        "        engine_power = None\n",
        "        km = None\n",
        "        mileage = None\n",
        "        city = None\n",
        "        brand = None\n",
        "        model = None\n",
        "        body_type = None\n",
        "        transmission = None\n",
        "        drive_type = None\n",
        "        number_of_seats = None\n",
        "        owners = None\n",
        "        condition = None\n",
        "        market_adapted_for = None\n",
        "\n",
        "        # Safely extract 'name'\n",
        "        name_tag = el.find('div', {'class': 'products-i__name products-i__bottom-text'})\n",
        "        if name_tag:\n",
        "            name = name_tag.text.strip()\n",
        "            # Extract brand and model from name\n",
        "            if name:\n",
        "                name_parts = name.split()\n",
        "                if len(name_parts) >= 2:\n",
        "                    brand = name_parts[0]\n",
        "                    model = ' '.join(name_parts[1:])\n",
        "\n",
        "        # Safely extract 'price' and 'currency'\n",
        "        price_tag = el.find('div', {'class': 'products-i__price products-i__bottom-text'})\n",
        "        if price_tag:\n",
        "            full_price_text = price_tag.text.replace(' ', '').strip()\n",
        "            if full_price_text:\n",
        "                currency = full_price_text[-1]\n",
        "                price = full_price_text[:-1]\n",
        "\n",
        "        # Safely extract 'year', 'engine_power', 'km'\n",
        "        attributes_tag = el.find('div', {'class': 'products-i__attributes products-i__bottom-text'})\n",
        "        if attributes_tag:\n",
        "            attributes_text = attributes_tag.text.strip()\n",
        "            parts = attributes_text.split(',')\n",
        "            if len(parts) > 0:\n",
        "                year = parts[0].strip()\n",
        "            if len(parts) > 1:\n",
        "                engine_power = parts[1].strip()\n",
        "            if len(parts) > 2:\n",
        "                km = parts[2].strip()\n",
        "                mileage = km  # km and mileage are the same\n",
        "\n",
        "        # Extract city (location)\n",
        "        city_tag = el.find('div', {'class': 'products-i__city products-i__bottom-text'})\n",
        "        if city_tag:\n",
        "            city = city_tag.text.strip()\n",
        "\n",
        "        # Look for additional details in description or other elements\n",
        "        # This might be in a different container - you may need to adjust selectors\n",
        "        details_container = el.find_parent().find('div', class_='products-i')\n",
        "\n",
        "        if details_container:\n",
        "            # Look for additional attributes that might be in data attributes or other elements\n",
        "            # Extract body type, transmission, etc. from additional info\n",
        "            info_elements = details_container.find_all('span', class_='products-i__info')\n",
        "\n",
        "            for info in info_elements:\n",
        "                info_text = info.text.lower().strip()\n",
        "\n",
        "                # Body type detection\n",
        "                if any(body in info_text for body in ['sedan', 'suv', 'hatchback', 'coupe', 'wagon', 'pickup']):\n",
        "                    body_type = info.text.strip()\n",
        "\n",
        "                # Transmission detection\n",
        "                elif any(trans in info_text for trans in ['automatic', 'manual', 'variator', 'robot']):\n",
        "                    transmission = info.text.strip()\n",
        "\n",
        "                # Drive type detection\n",
        "                elif any(drive in info_text for drive in ['front', 'rear', 'all', '4wd', 'awd']):\n",
        "                    drive_type = info.text.strip()\n",
        "\n",
        "                # Number of seats\n",
        "                elif 'seat' in info_text or info_text.isdigit():\n",
        "                    if info_text.isdigit() and int(info_text) <= 9:\n",
        "                        number_of_seats = info.text.strip()\n",
        "\n",
        "                # Condition\n",
        "                elif any(cond in info_text for cond in ['new', 'used', 'damaged', 'excellent']):\n",
        "                    condition = info.text.strip()\n",
        "\n",
        "        # Try to extract additional info from link or data attributes\n",
        "        link_element = el.find_parent().find('a')\n",
        "        if link_element:\n",
        "            # Sometimes additional data is stored in data attributes\n",
        "            data_attrs = link_element.attrs\n",
        "            for attr, value in data_attrs.items():\n",
        "                if 'body' in attr.lower():\n",
        "                    body_type = value\n",
        "                elif 'transmission' in attr.lower():\n",
        "                    transmission = value\n",
        "                elif 'drive' in attr.lower():\n",
        "                    drive_type = value\n",
        "\n",
        "        # Look for owner count in the listing\n",
        "        owner_pattern = re.search(r'(\\d+)\\s*owner', el.get_text(), re.IGNORECASE)\n",
        "        if owner_pattern:\n",
        "            owners = owner_pattern.group(1)\n",
        "\n",
        "        # Market adaptation (usually mentioned in description)\n",
        "        if 'local' in el.get_text().lower():\n",
        "            market_adapted_for = 'Local'\n",
        "        elif 'import' in el.get_text().lower():\n",
        "            market_adapted_for = 'Import'\n",
        "\n",
        "        car_results.append({\n",
        "            'name': name,\n",
        "            'brand': brand,\n",
        "            'model': model,\n",
        "            'price': price,\n",
        "            'currency': currency,\n",
        "            'year': year,\n",
        "            'engine_power': engine_power,\n",
        "            'km': km,\n",
        "            'mileage': mileage,\n",
        "            'city': city,\n",
        "            'body_type': body_type,\n",
        "            'transmission': transmission,\n",
        "            'drive_type': drive_type,\n",
        "            'number_of_seats': number_of_seats,\n",
        "            'owners': owners,\n",
        "            'condition': condition,\n",
        "            'market_adapted_for': market_adapted_for\n",
        "        })\n",
        "\n",
        "# Create DataFrame from the collected results\n",
        "cars = pd.DataFrame(car_results)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(\"\\nDataFrame created successfully. First 5 rows:\")\n",
        "print(cars.head())\n",
        "\n",
        "# Display column info\n",
        "print(\"\\nDataFrame info:\")\n",
        "print(cars.info())\n",
        "\n",
        "# Save to CSV\n",
        "cars.to_csv('turbo_az_cars.csv', index=False, encoding='utf-8')\n",
        "print(\"\\nData saved to 'turbo_az_cars.csv'\")\n",
        "\n",
        "# Display summary statistics\n",
        "print(\"\\nSummary of extracted data:\")\n",
        "print(f\"Total cars scraped: {len(cars)}\")\n",
        "print(f\"Unique brands: {cars['brand'].nunique()}\")\n",
        "print(f\"Unique cities: {cars['city'].nunique()}\")\n",
        "print(f\"Price range: {cars['price'].min()} - {cars['price'].max()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg-b5eGoeQQ0",
        "outputId": "840c0c82-a4c0-4739-8396-27ff2d46191c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page: 1\n",
            "Scraping page: 2\n",
            "Scraping page: 3\n",
            "Scraping page: 4\n",
            "Scraping page: 5\n",
            "Scraping page: 6\n",
            "Scraping page: 7\n",
            "Scraping page: 8\n",
            "Scraping page: 9\n",
            "\n",
            "DataFrame created successfully. First 5 rows:\n",
            "                      name     brand           model    price currency  year  \\\n",
            "0              Kia Sorento       Kia         Sorento  82900AZ        N  2024   \n",
            "1  Mercedes GLS 450 4MATIC  Mercedes  GLS 450 4MATIC   142000        $  2023   \n",
            "2            Nissan Patrol    Nissan          Patrol   124900        $  2025   \n",
            "3      Jeep Grand Cherokee      Jeep  Grand Cherokee  28500AZ        N  2013   \n",
            "4           Hyundai Accent   Hyundai          Accent  11200AZ        N  2008   \n",
            "\n",
            "  engine_power          km     mileage  city body_type transmission  \\\n",
            "0        2.2 L        0 km        0 km  None      None         None   \n",
            "1        3.0 L        0 km        0 km  None      None         None   \n",
            "2        3.5 L        0 km        0 km  None      None         None   \n",
            "3        3.6 L  156 000 km  156 000 km  None      None         None   \n",
            "4        1.4 L  227 000 km  227 000 km  None      None         None   \n",
            "\n",
            "  drive_type number_of_seats owners condition market_adapted_for  \n",
            "0       None            None   None      None               None  \n",
            "1       None            None   None      None               None  \n",
            "2       None            None   None      None               None  \n",
            "3       None            None   None      None               None  \n",
            "4       None            None   None      None               None  \n",
            "\n",
            "DataFrame info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 324 entries, 0 to 323\n",
            "Data columns (total 17 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   name                324 non-null    object\n",
            " 1   brand               324 non-null    object\n",
            " 2   model               324 non-null    object\n",
            " 3   price               324 non-null    object\n",
            " 4   currency            324 non-null    object\n",
            " 5   year                320 non-null    object\n",
            " 6   engine_power        320 non-null    object\n",
            " 7   km                  317 non-null    object\n",
            " 8   mileage             317 non-null    object\n",
            " 9   city                0 non-null      object\n",
            " 10  body_type           0 non-null      object\n",
            " 11  transmission        0 non-null      object\n",
            " 12  drive_type          0 non-null      object\n",
            " 13  number_of_seats     0 non-null      object\n",
            " 14  owners              0 non-null      object\n",
            " 15  condition           0 non-null      object\n",
            " 16  market_adapted_for  0 non-null      object\n",
            "dtypes: object(17)\n",
            "memory usage: 43.2+ KB\n",
            "None\n",
            "\n",
            "Data saved to 'turbo_az_cars.csv'\n",
            "\n",
            "Summary of extracted data:\n",
            "Total cars scraped: 324\n",
            "Unique brands: 47\n",
            "Unique cities: 0\n",
            "Price range: 10500AZ - 9850AZ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Initialize an empty list to store car results\n",
        "car_results = []\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "for page_number in range(1, 5):\n",
        "    url = f'https://turbo.az/autos?page={page_number}'\n",
        "    print(f\"Scraping page: {page_number}\")\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request failed for page {page_number}: {e}\")\n",
        "        continue\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all car listing elements\n",
        "    listings = soup.find_all('div', {'class': 'products-i__bottom'})\n",
        "\n",
        "    if not listings:\n",
        "        print(f\"No listings found on page {page_number}. Stopping.\")\n",
        "        break\n",
        "\n",
        "    for el in listings:\n",
        "        # Initialize all variables\n",
        "        name = None\n",
        "        price = None\n",
        "        currency = None\n",
        "        year = None\n",
        "        engine_power = None\n",
        "        km = None\n",
        "        mileage = None\n",
        "        city = None\n",
        "        brand = None\n",
        "        model = None\n",
        "        body_type = None\n",
        "        transmission = None\n",
        "        drive_type = None\n",
        "        number_of_seats = None\n",
        "        owners = None\n",
        "        condition = None\n",
        "        market_adapted_for = None\n",
        "\n",
        "        # Safely extract 'name'\n",
        "        name_tag = el.find('div', {'class': 'products-i__name products-i__bottom-text'})\n",
        "        if name_tag:\n",
        "            name = name_tag.text.strip()\n",
        "            # Extract brand and model from name\n",
        "            if name:\n",
        "                name_parts = name.split()\n",
        "                if len(name_parts) >= 2:\n",
        "                    brand = name_parts[0]\n",
        "                    model = ' '.join(name_parts[1:])\n",
        "\n",
        "        # Safely extract 'price' and 'currency'\n",
        "        price_tag = el.find('div', {'class': 'products-i__price products-i__bottom-text'})\n",
        "        if price_tag:\n",
        "            full_price_text = price_tag.text.replace(' ', '').replace(',', '').strip()\n",
        "            if full_price_text:\n",
        "                # Check if price contains currency symbol at the end\n",
        "                if full_price_text[-1] in ['₼', '$', '€']:\n",
        "                    currency = full_price_text[-1]\n",
        "                    price = full_price_text[:-1]\n",
        "                # If no currency symbol, check if it's all digits (likely AZN)\n",
        "                elif full_price_text.replace('.', '').isdigit():\n",
        "                    currency = 'AZN'  # Default to AZN when no currency symbol\n",
        "                    price = full_price_text\n",
        "                else:\n",
        "                    # Try to extract numbers and assume AZN\n",
        "                    price_numbers = re.findall(r'\\d+', full_price_text)\n",
        "                    if price_numbers:\n",
        "                        price = ''.join(price_numbers)\n",
        "                        currency = 'AZN'\n",
        "\n",
        "        # Safely extract 'year', 'engine_power', 'km'\n",
        "        attributes_tag = el.find('div', {'class': 'products-i__attributes products-i__bottom-text'})\n",
        "        if attributes_tag:\n",
        "            attributes_text = attributes_tag.text.strip()\n",
        "            parts = attributes_text.split(',')\n",
        "            if len(parts) > 0:\n",
        "                year = parts[0].strip()\n",
        "            if len(parts) > 1:\n",
        "                engine_power = parts[1].strip()\n",
        "            if len(parts) > 2:\n",
        "                km = parts[2].strip()\n",
        "                mileage = km  # km and mileage are the same\n",
        "\n",
        "        # Extract city (location) - try multiple possible selectors\n",
        "        city_selectors = [\n",
        "            'div.products-i__city',\n",
        "            'div.products-i__location',\n",
        "            'span.products-i__city',\n",
        "            'div[class*=\"city\"]',\n",
        "            'div[class*=\"location\"]'\n",
        "        ]\n",
        "\n",
        "        for selector in city_selectors:\n",
        "            city_tag = el.find_next(selector.split('.')[0], {'class': selector.split('.')[1] if '.' in selector else None})\n",
        "            if city_tag:\n",
        "                city = city_tag.text.strip()\n",
        "                break\n",
        "\n",
        "        # If city not found in current element, try parent container\n",
        "        if not city:\n",
        "            parent_container = el.find_parent('div', class_='products-i')\n",
        "            if parent_container:\n",
        "                for selector in city_selectors:\n",
        "                    city_tag = parent_container.find(selector.split('.')[0], {'class': selector.split('.')[1] if '.' in selector else None})\n",
        "                    if city_tag:\n",
        "                        city = city_tag.text.strip()\n",
        "                        break\n",
        "\n",
        "        # Look for additional car details in the full listing container\n",
        "        # Get the parent container that has all the car information\n",
        "        full_listing = el.find_parent('div', class_='products-i') or el.find_parent('a')\n",
        "\n",
        "        if full_listing:\n",
        "            full_text = full_listing.get_text().lower()\n",
        "\n",
        "            # Extract additional details from any text content\n",
        "            detail_patterns = {\n",
        "                'body_type': ['sedan', 'suv', 'hatchback', 'coupe', 'wagon', 'pickup', 'crossover', 'minivan', 'roadster', 'universal'],\n",
        "                'transmission': ['avtomatik', 'mexaniki', 'variator', 'robot', 'automatic', 'manual'],\n",
        "                'drive_type': ['ön', 'arxa', 'tam', 'front', 'rear', 'all', '4wd', 'awd', 'fwd', 'rwd'],\n",
        "                'condition': ['yeni', 'işlənmiş', 'zədəli', 'new', 'used', 'damaged', 'excellent', 'normal'],\n",
        "                'market_adapted_for': ['yerli', 'xarici', 'local', 'import', 'imported']\n",
        "            }\n",
        "\n",
        "            for field, patterns in detail_patterns.items():\n",
        "                for pattern in patterns:\n",
        "                    if pattern in full_text:\n",
        "                        if field == 'body_type':\n",
        "                            body_type = pattern.title()\n",
        "                        elif field == 'transmission':\n",
        "                            transmission = pattern.title()\n",
        "                        elif field == 'drive_type':\n",
        "                            drive_type = pattern.title()\n",
        "                        elif field == 'condition':\n",
        "                            condition = pattern.title()\n",
        "                        elif field == 'market_adapted_for':\n",
        "                            market_adapted_for = 'Local' if pattern in ['yerli', 'local'] else 'Import'\n",
        "                        break\n",
        "\n",
        "            # Extract number of seats (look for patterns like \"5 yerlik\", \"7 seats\")\n",
        "            seat_pattern = re.search(r'(\\d+)\\s*(yerlik|seats?|oturacaq)', full_text)\n",
        "            if seat_pattern:\n",
        "                number_of_seats = seat_pattern.group(1)\n",
        "\n",
        "            # Extract number of owners\n",
        "            owner_patterns = [\n",
        "                r'(\\d+)\\s*(sahibli|owner|sahibi)',\n",
        "                r'sahibli[:\\s]*(\\d+)',\n",
        "                r'(\\d+)\\s*-ci\\s*sahibi'\n",
        "            ]\n",
        "            for pattern in owner_patterns:\n",
        "                owner_match = re.search(pattern, full_text)\n",
        "                if owner_match:\n",
        "                    owners = owner_match.group(1)\n",
        "                    break\n",
        "\n",
        "        # Additional extraction from link attributes or title\n",
        "        link_element = el.find_parent('a') or el.find('a')\n",
        "        if link_element:\n",
        "            title_attr = link_element.get('title', '')\n",
        "            if title_attr:\n",
        "                title_text = title_attr.lower()\n",
        "                # Extract additional info from title attribute\n",
        "                if not city and any(location in title_text for location in ['baku', 'ganja', 'sumgait', 'mingachevir']):\n",
        "                    for loc in ['baku', 'ganja', 'sumgait', 'mingachevir']:\n",
        "                        if loc in title_text:\n",
        "                            city = loc.title()\n",
        "                            break\n",
        "\n",
        "        car_results.append({\n",
        "            'name': name,\n",
        "            'brand': brand,\n",
        "            'model': model,\n",
        "            'price': price,\n",
        "            'currency': currency,\n",
        "            'year': year,\n",
        "            'engine_power': engine_power,\n",
        "            'km': km,\n",
        "            'mileage': mileage,\n",
        "            'city': city,\n",
        "            'body_type': body_type,\n",
        "            'transmission': transmission,\n",
        "            'drive_type': drive_type,\n",
        "            'number_of_seats': number_of_seats,\n",
        "            'owners': owners,\n",
        "            'condition': condition,\n",
        "            'market_adapted_for': market_adapted_for\n",
        "        })\n",
        "\n",
        "# Create DataFrame from the collected results\n",
        "cars = pd.DataFrame(car_results)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(\"\\nDataFrame created successfully. First 5 rows:\")\n",
        "print(cars.head())\n",
        "\n",
        "# Display column info\n",
        "print(\"\\nDataFrame info:\")\n",
        "print(cars.info())\n",
        "\n",
        "# Show non-empty data for missing fields\n",
        "print(\"\\nNon-empty data summary:\")\n",
        "for col in ['city', 'body_type', 'transmission', 'drive_type', 'number_of_seats', 'owners', 'condition', 'market_adapted_for']:\n",
        "    non_empty = cars[col].dropna()\n",
        "    print(f\"{col}: {len(non_empty)} non-empty values\")\n",
        "    if len(non_empty) > 0:\n",
        "        print(f\"  Sample values: {non_empty.unique()[:5]}\")\n",
        "\n",
        "# Save to CSV\n",
        "cars.to_csv('turbo_az_cars.csv', index=False, encoding='utf-8')\n",
        "print(\"\\nData saved to 'turbo_az_cars.csv'\")\n",
        "\n",
        "# Display summary statistics\n",
        "print(\"\\nSummary of extracted data:\")\n",
        "print(f\"Total cars scraped: {len(cars)}\")\n",
        "print(f\"Unique brands: {cars['brand'].nunique()}\")\n",
        "print(f\"Unique cities: {cars['city'].nunique()}\")\n",
        "if cars['price'].notna().any():\n",
        "    try:\n",
        "        # Convert price to numeric for statistics\n",
        "        numeric_prices = pd.to_numeric(cars['price'], errors='coerce')\n",
        "        print(f\"Price range: {numeric_prices.min():.0f} - {numeric_prices.max():.0f}\")\n",
        "    except:\n",
        "        print(\"Price statistics unavailable (non-numeric values)\")\n",
        "else:\n",
        "    print(\"No price data available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "asNpfh8nfmi1",
        "outputId": "2fbe18b2-853c-4494-9c7f-b15aa554b22a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page: 1\n",
            "Request failed for page 1: 403 Client Error: Forbidden for url: https://turbo.az/autos?page=1\n",
            "Scraping page: 2\n",
            "Request failed for page 2: 403 Client Error: Forbidden for url: https://turbo.az/autos?page=2\n",
            "Scraping page: 3\n",
            "Request failed for page 3: 403 Client Error: Forbidden for url: https://turbo.az/autos?page=3\n",
            "Scraping page: 4\n",
            "Request failed for page 4: 403 Client Error: Forbidden for url: https://turbo.az/autos?page=4\n",
            "\n",
            "DataFrame created successfully. First 5 rows:\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "\n",
            "DataFrame info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 0 entries\n",
            "Empty DataFrame\n",
            "None\n",
            "\n",
            "Non-empty data summary:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'city'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-14-3360817149.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nNon-empty data summary:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'city'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transmission'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'drive_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'number_of_seats'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'owners'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'condition'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'market_adapted_for'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0mnon_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{col}: {len(non_empty)} non-empty values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_empty\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'city'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Initialize an empty list to store car results\n",
        "car_results = []\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "# Define a dictionary of common attribute labels and their target variables (Azerbaijani to English)\n",
        "attribute_labels = {\n",
        "    'Ban növü': 'body_type',\n",
        "    'Sürətlər qutusu': 'transmission',\n",
        "    'Ötürücü': 'drive_type',\n",
        "    'Oturacaq sayı': 'number_of_seats',\n",
        "    'Sahiblər': 'owners',\n",
        "    'Vəziyyəti': 'condition',\n",
        "    'Bazara uyğunlaşma': 'market_adapted_for'\n",
        "}\n",
        "\n",
        "# Mapping of Azerbaijani/common values to standardized English terms\n",
        "value_mapping = {\n",
        "    'sedan': 'Sedan', 'suv': 'SUV', 'hetçbek': 'Hatchback', 'kupe': 'Coupe',\n",
        "    'universal': 'Wagon', 'pikap': 'Pickup', 'krossover': 'Crossover',\n",
        "    'minivan': 'Minivan', 'rodster': 'Roadster', 'limuzin': 'Limousine', # Added more body types\n",
        "    'avtomatik': 'Automatic', 'mexaniki': 'Manual', 'variator': 'Variator', 'robot': 'Robot',\n",
        "    'ön': 'Front-wheel drive', 'arxa': 'Rear-wheel drive', 'tam': 'All-wheel drive',\n",
        "    'new': 'New', 'yeni': 'New', 'used': 'Used', 'işlənmiş': 'Used', 'normal': 'Used',\n",
        "    'damaged': 'Damaged', 'zədəli': 'Damaged', 'əla': 'Used (Excellent)',\n",
        "    'yerli': 'Local Market', 'xarici': 'Imported Market', 'yerli bazar': 'Local Market',\n",
        "    'automatic': 'Automatic', 'manual': 'Manual', 'front': 'Front-wheel drive',\n",
        "    'rear': 'Rear-wheel drive', 'all': 'All-wheel drive', '4wd': 'All-wheel drive',\n",
        "    'awd': 'All-wheel drive', 'fwd': 'Front-wheel drive', 'rwd': 'Rear-wheel drive',\n",
        "    'excellent': 'Used (Excellent)'\n",
        "}\n",
        "\n",
        "\n",
        "for page_number in range(1, 5): # Looping through pages 1 to 4 as before\n",
        "    url = f'https://turbo.az/autos?page={page_number}'\n",
        "    print(f\"Scraping page: {page_number}\")\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request failed for page {page_number}: {e}\")\n",
        "        continue\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all car listing elements. Each 'products-i' div represents a full car listing.\n",
        "    listings = soup.find_all('div', {'class': 'products-i'})\n",
        "\n",
        "    if not listings:\n",
        "        print(f\"No listings found on page {page_number}. Stopping.\")\n",
        "        break\n",
        "\n",
        "    for listing_el in listings: # 'listing_el' now represents the entire product item div\n",
        "        # Initialize all variables for the current car\n",
        "        name = None\n",
        "        price = None\n",
        "        currency = None\n",
        "        year = None\n",
        "        engine_power = None\n",
        "        km = None\n",
        "        mileage = None\n",
        "        city = None\n",
        "        brand = None\n",
        "        model = None\n",
        "        body_type = None\n",
        "        transmission = None\n",
        "        drive_type = None\n",
        "        number_of_seats = None\n",
        "        owners = None\n",
        "        condition = None\n",
        "        market_adapted_for = None\n",
        "\n",
        "        # The 'products-i__bottom' div usually contains name, price, year, engine, km\n",
        "        bottom_el = listing_el.find('div', {'class': 'products-i__bottom'})\n",
        "\n",
        "        if bottom_el:\n",
        "            # Safely extract 'name'\n",
        "            name_tag = bottom_el.find('div', {'class': 'products-i__name products-i__bottom-text'})\n",
        "            if name_tag:\n",
        "                name = name_tag.text.strip()\n",
        "                # Extract brand and model from name (e.g., \"BMW X5\" -> Brand: BMW, Model: X5)\n",
        "                if name:\n",
        "                    name_parts = name.split(maxsplit=1) # Split only on the first space\n",
        "                    if len(name_parts) >= 1:\n",
        "                        brand = name_parts[0]\n",
        "                        if len(name_parts) > 1:\n",
        "                            model = name_parts[1]\n",
        "\n",
        "            # Safely extract 'price' and 'currency'\n",
        "            price_tag = bottom_el.find('div', {'class': 'products-i__price products-i__bottom-text'})\n",
        "            if price_tag:\n",
        "                full_price_text = price_tag.text.replace(' ', '').replace(',', '').strip()\n",
        "                if full_price_text:\n",
        "                    # Check if price contains currency symbol at the end\n",
        "                    if full_price_text and full_price_text[-1] in ['₼', '$', '€']:\n",
        "                        currency = full_price_text[-1]\n",
        "                        price = full_price_text[:-1]\n",
        "                    # If no currency symbol, check if it's all digits (likely AZN)\n",
        "                    elif full_price_text.replace('.', '').isdigit():\n",
        "                        currency = 'AZN'  # Default to AZN when no explicit symbol\n",
        "                        price = full_price_text\n",
        "                    else:\n",
        "                        # Try to extract numbers and assume AZN if other symbols are present\n",
        "                        price_numbers = re.findall(r'\\d+', full_price_text)\n",
        "                        if price_numbers:\n",
        "                            price = ''.join(price_numbers)\n",
        "                            currency = 'AZN' # Fallback to AZN if numbers are found without explicit currency\n",
        "\n",
        "            # Safely extract 'year', 'engine_power', 'km' from the attributes line\n",
        "            attributes_tag = bottom_el.find('div', {'class': 'products-i__attributes products-i__bottom-text'})\n",
        "            if attributes_tag:\n",
        "                attributes_text = attributes_tag.text.strip()\n",
        "                parts = attributes_text.split(',')\n",
        "                if len(parts) > 0:\n",
        "                    year = parts[0].strip()\n",
        "                if len(parts) > 1:\n",
        "                    engine_power = parts[1].strip() # Example: \"3.0 L\" or \"250 hp\"\n",
        "                if len(parts) > 2:\n",
        "                    km = parts[2].strip()\n",
        "                    mileage = km  # km and mileage are essentially the same value here\n",
        "\n",
        "        # --- Enhanced City Extraction ---\n",
        "        # City is typically found in a div with class 'products-i__city' within the main listing_el\n",
        "        city_tag = listing_el.find('div', {'class': 'products-i__city'})\n",
        "        if city_tag:\n",
        "            city = city_tag.text.strip()\n",
        "        else:\n",
        "            # Fallback: attempt to find common Azerbaijani city names within the full listing's text\n",
        "            city_pattern = r'\\b(Bakı|Gəncə|Sumqayıt|Mingəçevir|Naxçıvan|Lənkəran|Şəki|Quba|Qazax|Tovuz|Astara|Bərdə|Kürdəmir|Masallı|Qəbələ|Salyan|Şamaxı|Yevlax)\\b'\n",
        "            city_match = re.search(city_pattern, listing_el.get_text(), re.IGNORECASE)\n",
        "            if city_match:\n",
        "                city = city_match.group(1).title() # Capitalize the first letter of the found city name\n",
        "\n",
        "        # --- Enhanced Extraction for other detailed attributes (body_type, transmission, etc.) ---\n",
        "        # Look for a specific section that contains detailed attributes. This could be in a 'products-i__info' div\n",
        "        # or other elements within the main 'listing_el'.\n",
        "\n",
        "        # Prioritize the 'products-i__info' div for finding these details, fall back to the full listing_el\n",
        "        main_info_area = listing_el.find('div', {'class': 'products-i__info'}) or listing_el\n",
        "\n",
        "        if main_info_area:\n",
        "            # Search for various HTML elements that might contain attribute labels and their values.\n",
        "            # Using find_all with multiple tags to cover different structuring possibilities.\n",
        "            detail_elements = main_info_area.find_all(['div', 'span', 'li', 'p', 'h4', 'h5', 'td'])\n",
        "\n",
        "            for elem in detail_elements:\n",
        "                # Use separator=' ' to handle cases where value is in a nested tag\n",
        "                text_content = elem.get_text(separator=' ', strip=True)\n",
        "\n",
        "                for label_az, var_name in attribute_labels.items():\n",
        "                    # Create a regex pattern to find \"Label: Value\" or \"Label Value\"\n",
        "                    # re.escape() handles special characters in labels\n",
        "                    # (.+) captures the value after the label, non-greedily\n",
        "                    pattern = re.compile(rf'{re.escape(label_az)}\\s*[:]?\\s*(.+?)(?:\\s*,|\\s*$)', re.IGNORECASE)\n",
        "                    match = pattern.search(text_content)\n",
        "\n",
        "                    if match:\n",
        "                        value_raw = match.group(1).strip()\n",
        "                        # Standardize the extracted value using the value_mapping\n",
        "                        standardized_value = value_mapping.get(value_raw.lower(), value_raw)\n",
        "\n",
        "                        # Assign the standardized value to the correct variable\n",
        "                        if var_name == 'body_type':\n",
        "                            body_type = standardized_value\n",
        "                        elif var_name == 'transmission':\n",
        "                            transmission = standardized_value\n",
        "                        elif var_name == 'drive_type':\n",
        "                            drive_type = standardized_value\n",
        "                        elif var_name == 'number_of_seats':\n",
        "                            # Extract numbers only for seats\n",
        "                            num_match = re.search(r'\\d+', value_raw)\n",
        "                            if num_match:\n",
        "                                number_of_seats = num_match.group(0)\n",
        "                        elif var_name == 'owners':\n",
        "                            # Extract numbers only for owners\n",
        "                            num_match = re.search(r'\\d+', value_raw)\n",
        "                            if num_match:\n",
        "                                owners = num_match.group(0)\n",
        "                        elif var_name == 'condition':\n",
        "                            condition = standardized_value\n",
        "                        elif var_name == 'market_adapted_for':\n",
        "                            market_adapted_for = standardized_value\n",
        "                        # Once a match is found for a specific label, break to avoid reprocessing\n",
        "                        # and ensure the first found value is kept.\n",
        "                        break\n",
        "\n",
        "        # Append the collected data for the current car to the results list\n",
        "        car_results.append({\n",
        "            'name': name,\n",
        "            'brand': brand,\n",
        "            'model': model,\n",
        "            'price': price,\n",
        "            'currency': currency,\n",
        "            'year': year,\n",
        "            'engine_power': engine_power,\n",
        "            'km': km,\n",
        "            'mileage': mileage,\n",
        "            'city': city,\n",
        "            'body_type': body_type,\n",
        "            'transmission': transmission,\n",
        "            'drive_type': drive_type,\n",
        "            'number_of_seats': number_of_seats,\n",
        "            'owners': owners,\n",
        "            'condition': condition,\n",
        "            'market_adapted_for': market_adapted_for\n",
        "        })\n",
        "\n",
        "# Create DataFrame from the collected results\n",
        "cars = pd.DataFrame(car_results)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(\"\\nDataFrame created successfully. First 5 rows:\")\n",
        "print(cars.head())\n",
        "\n",
        "# Display column info\n",
        "print(\"\\nDataFrame info:\")\n",
        "print(cars.info())\n",
        "\n",
        "# Display summary statistics for currency issue debugging\n",
        "print(\"\\nCurrency distribution:\")\n",
        "print(cars['currency'].value_counts())\n",
        "print(\"\\nSample of price and currency data:\")\n",
        "print(cars[['name', 'price', 'currency']].head(10))\n",
        "\n",
        "# Show non-empty data for missing fields for verification\n",
        "print(\"\\nNon-empty data summary:\")\n",
        "for col in ['city', 'body_type', 'transmission', 'drive_type', 'number_of_seats', 'owners', 'condition', 'market_adapted_for']:\n",
        "    non_empty = cars[col].dropna()\n",
        "    print(f\"{col}: {len(non_empty)} non-empty values\")\n",
        "    if len(non_empty) > 0:\n",
        "        print(f\"  Sample values: {non_empty.unique()[:5]}\")\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "cars.to_csv('turbo_az_cars.csv', index=False, encoding='utf-8')\n",
        "print(\"\\nData saved to 'turbo_az_cars.csv'\")\n",
        "\n",
        "# Display overall summary statistics\n",
        "print(\"\\nSummary of extracted data:\")\n",
        "print(f\"Total cars scraped: {len(cars)}\")\n",
        "print(f\"Unique brands: {cars['brand'].nunique()}\")\n",
        "print(f\"Unique cities: {cars['city'].nunique()}\")\n",
        "if cars['price'].notna().any():\n",
        "    try:\n",
        "        # Convert price to numeric for statistics, coercing errors to NaN\n",
        "        numeric_prices = pd.to_numeric(cars['price'], errors='coerce')\n",
        "        print(f\"Price range: {numeric_prices.min():.0f} - {numeric_prices.max():.0f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Price statistics unavailable (error converting price: {e})\")\n",
        "else:\n",
        "    print(\"No price data available\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "DocTlNPkfnKX",
        "outputId": "979cccb1-f08b-4a2f-ac3a-4cdcbcc2ff1a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page: 1\n",
            "Request failed for page 1: 403 Client Error: Forbidden for url: https://turbo.az/autos?page=1\n",
            "Scraping page: 2\n",
            "Request failed for page 2: 403 Client Error: Forbidden for url: https://turbo.az/autos?page=2\n",
            "Scraping page: 3\n",
            "Request failed for page 3: 403 Client Error: Forbidden for url: https://turbo.az/autos?page=3\n",
            "Scraping page: 4\n",
            "Request failed for page 4: 403 Client Error: Forbidden for url: https://turbo.az/autos?page=4\n",
            "\n",
            "DataFrame created successfully. First 5 rows:\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "\n",
            "DataFrame info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 0 entries\n",
            "Empty DataFrame\n",
            "None\n",
            "\n",
            "Currency distribution:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'currency'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-15-1518621333.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;31m# Display summary statistics for currency issue debugging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nCurrency distribution:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'currency'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nSample of price and currency data:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'currency'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'currency'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WJf11V4_ufrK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}